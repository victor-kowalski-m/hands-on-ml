{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2ca1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import re\n",
    "import bz2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c78d33e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"https://spamassassin.apache.org\"\n",
    "SPAM_PATH = os.path.join(\"datasets\", \"spam\")\n",
    "SPAM_URL = DOWNLOAD_ROOT + \"/old/publiccorpus/\"\n",
    "\n",
    "def fetch_spam_data(spam_url=SPAM_URL, spam_path=SPAM_PATH):\n",
    "    os.makedirs(spam_path, exist_ok=True)\n",
    "    urlpath = urllib.request.urlopen('https://spamassassin.apache.org/old/publiccorpus/')\n",
    "    string = urlpath.read().decode('utf-8')\n",
    "    pattern = re.compile('href=\".*\\.bz2\"')\n",
    "    filelist = [f[6:-1] for f in pattern.findall(string)]\n",
    "    for f in filelist:\n",
    "        bz2path = os.path.join(spam_path, f)\n",
    "        urllib.request.urlretrieve(spam_url+f, bz2path)\n",
    "        with bz2.BZ2File(bz2path) as bz2_file:\n",
    "            data = bz2_file.read()\n",
    "        tarpath = bz2path[:-4]\n",
    "        open(tarpath, 'wb').write(data)\n",
    "        with tarfile.open(tarpath) as tar_file:\n",
    "            tar_file.extractall(path=spam_path)\n",
    "        os.remove(bz2path)\n",
    "        os.remove(tarpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3616772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch_spam_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "882e30fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "contents = []\n",
    "cats = []\n",
    "\n",
    "for cat in os.listdir(SPAM_PATH):\n",
    "    cat_path = os.path.join(SPAM_PATH, cat)\n",
    "    cat_files = os.listdir(cat_path)\n",
    "    cat_contents = [open(os.path.join(cat_path, f), encoding='ansi').read() for f in cat_files if f != \"cmds\"]\n",
    "    contents += cat_contents\n",
    "    cats += [cat] * len(cat_contents)\n",
    "    \n",
    "emails = pd.DataFrame(data={'Content': contents, 'Cat': cats})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfe0db23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9349 entries, 0 to 9348\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Content  9349 non-null   object\n",
      " 1   Cat      9349 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 146.2+ KB\n"
     ]
    }
   ],
   "source": [
    "emails.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be6f75d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "easy_ham      5051\n",
       "easy_ham_2    1400\n",
       "spam_2        1397\n",
       "spam          1001\n",
       "hard_ham       500\n",
       "Name: Cat, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails['Cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06d9e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails[\"Cat\"] = emails.apply(lambda row: row[\"Cat\"][:-2] if (row[\"Cat\"][-2] == '_' and row[\"Cat\"][-1].isdigit()) else row[\"Cat\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a145969",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "easy_ham    0.690020\n",
       "spam        0.256498\n",
       "hard_ham    0.053482\n",
       "Name: Cat, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails['Cat'].value_counts()/len(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "579ba432",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails['Label'] = emails['Cat'].str.contains('spam').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2742534d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Cat</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From exmh-workers-admin@redhat.com  Thu Aug 22...</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From Steve_Burt@cursor-system.com  Thu Aug 22 ...</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From timc@2ubh.com  Thu Aug 22 13:52:59 2002\\n...</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From irregulars-admin@tb.tf  Thu Aug 22 14:23:...</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From Stewart.Smith@ee.ed.ac.uk  Thu Aug 22 14:...</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9344</th>\n",
       "      <td>From Professional_Career_Development_Institute...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9345</th>\n",
       "      <td>From tba@insiq.us  Wed Dec  4 11:46:34 2002\\nR...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9346</th>\n",
       "      <td>Return-Path: &lt;raye@yahoo.lv&gt;\\nReceived: from u...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9347</th>\n",
       "      <td>From cweqx@dialix.oz.au  Tue Aug  6 11:03:54 2...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9348</th>\n",
       "      <td>From ilug-admin@linux.ie  Wed Dec  4 11:52:36 ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9349 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Content       Cat  Label\n",
       "0     From exmh-workers-admin@redhat.com  Thu Aug 22...  easy_ham      0\n",
       "1     From Steve_Burt@cursor-system.com  Thu Aug 22 ...  easy_ham      0\n",
       "2     From timc@2ubh.com  Thu Aug 22 13:52:59 2002\\n...  easy_ham      0\n",
       "3     From irregulars-admin@tb.tf  Thu Aug 22 14:23:...  easy_ham      0\n",
       "4     From Stewart.Smith@ee.ed.ac.uk  Thu Aug 22 14:...  easy_ham      0\n",
       "...                                                 ...       ...    ...\n",
       "9344  From Professional_Career_Development_Institute...      spam      1\n",
       "9345  From tba@insiq.us  Wed Dec  4 11:46:34 2002\\nR...      spam      1\n",
       "9346  Return-Path: <raye@yahoo.lv>\\nReceived: from u...      spam      1\n",
       "9347  From cweqx@dialix.oz.au  Tue Aug  6 11:03:54 2...      spam      1\n",
       "9348  From ilug-admin@linux.ie  Wed Dec  4 11:52:36 ...      spam      1\n",
       "\n",
       "[9349 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b72736ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(emails, emails[\"Cat\"]):\n",
    "    strat_train_set = emails.loc[train_index]\n",
    "    strat_test_set = emails.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d9b20e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "easy_ham    0.690066\n",
       "spam        0.256451\n",
       "hard_ham    0.053483\n",
       "Name: Cat, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set['Cat'].value_counts()/len(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10b8b5e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "easy_ham    0.689840\n",
       "spam        0.256684\n",
       "hard_ham    0.053476\n",
       "Name: Cat, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_test_set['Cat'].value_counts()/len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1e8f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = strat_train_set.drop(columns=[\"Cat\", \"Label\"]), strat_train_set[\"Label\"].copy(), strat_test_set.drop(columns=[\"Cat\", \"Label\"]), strat_test_set[\"Label\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33a1737e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Cat</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From exmh-workers-admin@redhat.com  Thu Aug 22...</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From Steve_Burt@cursor-system.com  Thu Aug 22 ...</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From timc@2ubh.com  Thu Aug 22 13:52:59 2002\\n...</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From irregulars-admin@tb.tf  Thu Aug 22 14:23:...</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From Stewart.Smith@ee.ed.ac.uk  Thu Aug 22 14:...</td>\n",
       "      <td>easy_ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9344</th>\n",
       "      <td>From Professional_Career_Development_Institute...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9345</th>\n",
       "      <td>From tba@insiq.us  Wed Dec  4 11:46:34 2002\\nR...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9346</th>\n",
       "      <td>Return-Path: &lt;raye@yahoo.lv&gt;\\nReceived: from u...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9347</th>\n",
       "      <td>From cweqx@dialix.oz.au  Tue Aug  6 11:03:54 2...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9348</th>\n",
       "      <td>From ilug-admin@linux.ie  Wed Dec  4 11:52:36 ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9349 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Content       Cat  Label\n",
       "0     From exmh-workers-admin@redhat.com  Thu Aug 22...  easy_ham      0\n",
       "1     From Steve_Burt@cursor-system.com  Thu Aug 22 ...  easy_ham      0\n",
       "2     From timc@2ubh.com  Thu Aug 22 13:52:59 2002\\n...  easy_ham      0\n",
       "3     From irregulars-admin@tb.tf  Thu Aug 22 14:23:...  easy_ham      0\n",
       "4     From Stewart.Smith@ee.ed.ac.uk  Thu Aug 22 14:...  easy_ham      0\n",
       "...                                                 ...       ...    ...\n",
       "9344  From Professional_Career_Development_Institute...      spam      1\n",
       "9345  From tba@insiq.us  Wed Dec  4 11:46:34 2002\\nR...      spam      1\n",
       "9346  Return-Path: <raye@yahoo.lv>\\nReceived: from u...      spam      1\n",
       "9347  From cweqx@dialix.oz.au  Tue Aug  6 11:03:54 2...      spam      1\n",
       "9348  From ilug-admin@linux.ie  Wed Dec  4 11:52:36 ...      spam      1\n",
       "\n",
       "[9349 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "451d1687",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import email\n",
    "from email_reply_parser import EmailReplyParser\n",
    "\n",
    "# column index\n",
    "content_ix = 0\n",
    "\n",
    "class MyEmailParser(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, check_html=True): # no *args or **kargs\n",
    "        self.strip_headers = strip_headers\n",
    "        self.check_html = check_html\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        X_og = X.copy()\n",
    "        \n",
    "        if self.strip_headers:\n",
    "            new_contents = []\n",
    "            for email_content in X_og[:, content_ix]:\n",
    "                new = ''\n",
    "                message = email.message_from_string(email_content)\n",
    "                if message.is_multipart():\n",
    "                    for payload in message.get_payload():\n",
    "                        if payload.get_content_type() == \"text/plain\":\n",
    "                            new += payload.get_payload()     \n",
    "                else:\n",
    "                    new = message.get_payload()\n",
    "                new_contents += [new]\n",
    "            X[:, content_ix] = np.array(new_contents)\n",
    "        \n",
    "        if self.check_html:\n",
    "            have_html = np.empty((X.shape[0], 1))\n",
    "            for email_content in X_og[:, content_ix]:\n",
    "                has_html = False\n",
    "                if message.is_multipart():\n",
    "                    for payload in message.get_payload():\n",
    "                        if payload.get_content_type() == \"text/html\":\n",
    "                            has_html = True\n",
    "                else:\n",
    "                    has_html = message.get_content_type() == \"text/html\"\n",
    "                np.append(have_html, has_html)\n",
    "                np.c_[X, have_html.astype(int)]\n",
    "            \n",
    "        return X\n",
    "\n",
    "email_parser = MyEmailParser()\n",
    "parsed_emails = email_parser.transform(emails[emails.Content.str.contains('text/html')].values[0:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fdb75f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To view this newsletter in full-color:\n",
      "http://newsletter.mediaunspun.com/index000021410.cfm\n",
      "\n",
      "Media Unspun\n",
      "What the Press is Reporting and Why (www.mediaunspun.com)\n",
      "-----------------------------------------------------------------\n",
      "October 8, 2002\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "IN THIS ISSUE\n",
      "-----------------------------------------------------------------\n",
      "* BUSH COVERS THE WATERFRONT\n",
      "* THE BIGGEST CABLE HOOKUP\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "EDITOR'S NOTE\n",
      "-----------------------------------------------------------------\n",
      "Is Media Unspun useful to you? Then pass it on to a colleague.\n",
      "The more readers we have, the more successful we'll be. The more \n",
      "successful we are, the more useful we can be to you. Pass it\n",
      "on!\n",
      "\n",
      "Media Unspun serves business news and analysis, authoritatively\n",
      "and irreverently, every business day. An annual subscription\n",
      "costs $50, less than a dollar a week. If your four-week free\n",
      "trial is coming to an end soon, please visit\n",
      "http://www.mediaunspun.com/subscribe.html and sign up via credit card \n",
      "or check.\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "ADVERTISEMENT\n",
      "-----------------------------------------------------------------\n",
      "Pop!Tech 2002\n",
      "October 18 - 20, 2002: Camden, Maine\n",
      "Join 500 big thinkers to discuss\n",
      "the collision of technology and culture\n",
      "Register now at: http://www.poptech.org\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "BUSH COVERS THE WATERFRONT\n",
      "-----------------------------------------------------------------\n",
      "It may seem like all Iraq, all the time in the Oval Office, but\n",
      "the president has at least one other thing on his mind this\n",
      "week: that pesky port lockout. The freight still isn't moving,\n",
      "factories are running out of parts, produce is rotting, and\n",
      "retailers are more freaked about Christmas with every passing\n",
      "day. \n",
      "\n",
      "On Monday, Bush stepped in and appointed a three-member panel to \n",
      "see how badly this shutdown is hosing the economy. (We hope this \n",
      "isn't a difficult question, as the panel's been given all of one \n",
      "day to report back.) When Bush gets the report on Tuesday, the\n",
      "next step might be a court order to reopen the ports under the\n",
      "1947 Taft-Hartley Act. That would send employees back to work\n",
      "for 80 days while federal mediators duke it out over the\n",
      "disputed contract and retailers lower their Xanax dosages.\n",
      "\n",
      "Invoking Taft-Hartley requires a threat to national health or\n",
      "safety -- not the economy. But Labor Secretary Elaine Chao\n",
      "covered that base in a statement on Monday, saying the work\n",
      "stoppage threatens the flow of supplies to the military (we knew \n",
      "Iraq would be in here somewhere). \"Union officials quickly\n",
      "responded that their members have been unloading military cargo\n",
      "throughout the 10-day shutdown,\" said the L.A. Times, but an\n",
      "anonymous Bush administration official \"said that only a portion \n",
      "of what the Defense Department needs has made it ashore.\"\n",
      "\n",
      "Politically, this has been a tricky one. Using Taft-Hartley\n",
      "would annoy labor right before congressional elections. On the\n",
      "other hand, \"Voter discontent with Bush's handling of the\n",
      "increasingly fragile economic recovery has begun showing up in\n",
      "polls, and such concerns may have outweighed the political\n",
      "danger to the Republican administration,\" said the San Francisco \n",
      "Chronicle. Also, Bush stepped in on the same day that a poll\n",
      "reported two-thirds of Americans wanted him to focus more on the \n",
      "economy. \"Though the administration promised an unbiased\n",
      "examination of the lockout, Bush appeared to have made up his\n",
      "mind that it was hurting national security and the economy,\n",
      "andmerited federal intervention,\" said the AP. \n",
      "\n",
      "As for Taft-Hartley, it's not exactly famous for solving labor\n",
      "disputes. Often the 80-day cooling-off period ends, and workers\n",
      "simply walk out again (or get locked out again, in this case).\n",
      "One gets the sense, however, that fixing the dockworkers'\n",
      "contract isn't the point of this particular 80 days. It's 78\n",
      "days until Christmas. The race is on. - Jen Muehlbauer\n",
      "\n",
      "President Acts To Halt Port Lockout for 80 Days (Seattle\n",
      "Times)\n",
      "http://tinyurl.com/1usn\n",
      "\n",
      "Bush Expected To Act on Ports Crisis \n",
      "http://www.accessatlanta.com/ajc/business/1002/08ports.html\n",
      "\n",
      "President Moves Toward Forcing the Reopening of West Coast\n",
      "Ports\n",
      "http://www.latimes.com/business/la-fi-ports8oct08001439,0,1021983.story\n",
      "\n",
      "\n",
      "Bush Takes Step Toward Halting Lockout After West Coast Port\n",
      "Talks Break Off (AP)\n",
      "http://tinyurl.com/1usk\n",
      "\n",
      "White House Intervenes on Docks Dispute (Financial Times)\n",
      "http://tinyurl.com/1usm\n",
      "\n",
      "Cooling-off Period Likely in Port Fight (SF Chronicle)\n",
      "http://tinyurl.com/1usp\n",
      "\n",
      "Bush Moves Toward Halting Port Shutdown\n",
      "http://www.nytimes.com/2002/10/08/national/08PORT.html\n",
      "\n",
      "Trouble On The Docks\n",
      "http://online.wsj.com/page/0,,2_0864,00.html\n",
      "(Paid subscription required.)\n",
      "\n",
      "Charges of Politics Have Dogged Taft-Hartley Act\n",
      "http://seattlepi.nwsource.com/business/90243_hartley08.shtml\n",
      "\n",
      "Taft-Hartley Act No Quick-Fix For Port Dispute (Reuters)\n",
      "http://www.forbes.com/work/newswire/2002/10/02/rtr739458.html\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "ADVERTISEMENT\n",
      "-----------------------------------------------------------------\n",
      "SPECIAL OFFER!   Save 24% on a subscription to MIT TECHNOLOGY\n",
      "REVIEW. Get an inside view into the technologies, deals, and\n",
      "companies emerging from one of the leading research institutes\n",
      "-- MIT. \n",
      "http://www.technologyinsider.com/new/news1 \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "THE BIGGEST CABLE HOOKUP\n",
      "-----------------------------------------------------------------\n",
      "wo birds want to join forces and the FCC is about to cry \"fowl.\" \n",
      "We mean \"foul.\" The two dominant direct broadcast satellite\n",
      "players want to join forces, the better to compete with Big\n",
      "Cable. Federal regulators, both the FCC and the Justice\n",
      "Department, are concerned that the resulting conglomerate of\n",
      "DirecTV with Dish Network would command roughly 95% of satellite \n",
      "service in the US.\n",
      "\n",
      "The press could not settle on a price tag for the proposed\n",
      "merger between EchoStar Communications and Hughes Electronics -- \n",
      "it was described as being worth anywhere from $15 billion and\n",
      "$25 billion. It was a challenge to keep the players straight, as \n",
      "some outlets talked of a merger between the corporate parents,\n",
      "and others referred to the service monikers. Hughes is DirecTV\n",
      "and EchoStar is Dish. All straight?\n",
      "\n",
      "The two companies sent a letter to the FCC urging them to hold\n",
      "off ruling on (read, rejecting) the merger until the Justice\n",
      "Department has spoken. EchoStar and Hughes offered unspecified\n",
      "\"major revisions\" to the deal that they want to discuss with\n",
      "Justice in the next weeks.\n",
      "\n",
      "The Wall Street Journal delved deeply into the form those\n",
      "revisions could take -- specifically, selling some frequencies\n",
      "to Cablevision. The Journal reported that Cablevision has wanted \n",
      "to get into the satellite business for 10 years and outlined the \n",
      "cable company's plans and past spending on such a project.\n",
      "\n",
      "TheStreet.com turned in an extensive analysis of the deal for\n",
      "investors in the satellite space. It seems the market for\n",
      "expanded-service television may be nearing saturation.\n",
      "TheStreet.com quoted an analyst's report which concluded,\n",
      "\"Consumers should benefit from ... continued rivalry, but\n",
      "shareholders may realize much smaller returns.\"\n",
      "\n",
      "The New York Times and the Journal both mentioned Rupert Murdoch \n",
      "waiting in the wings. Last year Murdoch's News Corp. bid for\n",
      "DirecTV, but lost out at the last minute to EchoStar. If the\n",
      "current deal falls through, he'll be back. - Keith Dawson\n",
      "\n",
      "EchoStar and Hughes Propose Concessions in Bid to Save Deal\n",
      "http://online.wsj.com/article/0,,SB103403314258094560,00.html\n",
      "(Paid subscription required)\n",
      "\n",
      "Regulators Set to Block EchoStar's Hughes Purchase\n",
      "http://online.wsj.com/article/0,,SB1033939901346228393,00.html\n",
      "(Paid subscription required)\n",
      "\n",
      "'Last-ditch effort' (Rocky Mountain News)\n",
      "http://tinyurl.com/1upi\n",
      "\n",
      "EchoStar, Hughes See a Glimmer of Hope\n",
      "http://www.thestreet.com/tech/georgemannes/10046366.html\n",
      "\n",
      "F.C.C. Asked to Put Off Merger Ruling\n",
      "http://www.nytimes.com/2002/10/08/business/media/08BIRD.html\n",
      "\n",
      "EchoStar, Hughes ask FCC to defer decision\n",
      "http://www.nypost.com/business/59145.htm\n",
      "\n",
      "EchoStar, Hughes offer merger changes (Reuters) \n",
      "http://news.com.com/2100-1023-961138.html\n",
      "\n",
      "Delay in satellite-TV merger OK requested (AP)\n",
      "http://www.bayarea.com/mld/mercurynews/business/4236430.htm\n",
      "\n",
      "EchoStar, Hughes Seek to Delay Ruling\n",
      "http://www.latimes.com/technology/la-fi-echo8oct08,0,3454976.story\n",
      "\n",
      "\n",
      "EchoStar pleads to FCC on merger (Denver Post)\n",
      "http://tinyurl.com/1ut7\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "OTHER STORIES\n",
      "-----------------------------------------------------------------\n",
      "SEC Probes AOL-Oxygen Pact For Double-Booking of Revenue\n",
      "http://online.wsj.com/article/0,,SB1033938113684731193,00.html\n",
      "(Paid subscription required.)\n",
      "\n",
      "Tivo Raises $25 Million in Stock Offering (AP)\n",
      "http://www.siliconvalley.com/mld/siliconvalley/4235118.htm\n",
      "\n",
      "WorldCom Officer Pleads Guilty to Fraud\n",
      "http://www.washingtonpost.com/wp-dyn/articles/A57300-2002Oct7.html\n",
      "\n",
      "\n",
      "Two Magazines Are Shut and a Third Revamps\n",
      "http://www.nytimes.com/2002/10/08/business/media/08MAG.html\n",
      "\n",
      "Regulators Say They Have CSFB 'Smoking Gun'\n",
      "http://www.usatoday.com/money/industries/banking/2002-10-06-csfb_x.htm\n",
      "\n",
      "\n",
      "Expected Cold Winter Could Increase Natural Gas Prices \n",
      "http://www.accessatlanta.com/ajc/business/1002/08gas.html\n",
      "\n",
      "Frozen World Found Beyond Pluto\n",
      "http://www.msnbc.com/news/818195.asp\n",
      "\n",
      "Fool Me Once\n",
      "http://www.nytimes.com/2002/10/08/opinion/08KRUG.html\n",
      "\n",
      "New Northwest System for Internet Bookings\n",
      "http://www.nytimes.com/2002/10/08/business/08MEMO.html\n",
      "\n",
      "The Fastest-Growing Tech Companies\n",
      "http://www.business2.com/b2100/0,,1-1,00.html\n",
      "\n",
      "Debating the Baby Bells\n",
      "http://www.nytimes.com/2002/10/07/business/07PLAC.html\n",
      "(Paid subscription required)\n",
      "\n",
      "Silicon Valley Is Yearning For User-Friendly Microsoft\n",
      "http://online.wsj.com/article/0,,SB1034036651300028760,00.html\n",
      "(Paid subscription required)\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "Do you want to reach the Net's savviest audience?\n",
      "Advertise in Media Unspun.\n",
      "Contact Erik Vanderkolk for details at erikvanderkolk@yahoo.com \n",
      "today.\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "STAFF\n",
      "-----------------------------------------------------------------\n",
      "Written by Deborah Asbrand (dasbrand@world.std.com), Keith\n",
      "Dawson (dawson@world.std.com), Jen Muehlbauer\n",
      "(jen@englishmajor.com), and Lori Patel (loripatel@hotmail.com).\n",
      "\n",
      "Copyedited by Jim Duffy (jimduffy86@yahoo.com). \n",
      "Advertising: Erik Vanderkolk (erikvanderkolk@yahoo.com). \n",
      "Editor and publisher: Jimmy Guterman (guterman@vineyard.com).\n",
      "\n",
      "Media Unspun is produced by The Vineyard Group Inc. \n",
      "Copyright 2002 Media Unspun, Inc., and The Vineyard Group, Inc.\n",
      "\n",
      "Subscribe already, willya? http://www.mediaunspun.com\n",
      " \n",
      "Redistribution by email is permitted as long as a link to\n",
      "http://newsletter.mediaunspun.com is included.\n",
      "\n",
      "\n",
      "-|________________\n",
      "POWERED BY: http://www.imakenews.com\n",
      "To be removed from this list, use this link:\n",
      "http://www.imakenews.com/eletra/remove.cfm?x=mediaunspun%2Czzzz-unspun@spamassassin.taint.org\n",
      "To receive future messages in HTML format, use this link:\n",
      "http://www.imakenews.com/eletra/change.cfm?x=mediaunspun%2Czzzz-unspun@spamassassin.taint.org%2Chtm\n",
      "To change your subscriber information, use this link:\n",
      "http://www.imakenews.com/eletra/update.cfm?x=mediaunspun%2Czzzz-unspun@spamassassin.taint.org\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(parsed_emails[1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fba0a9",
   "metadata": {},
   "source": [
    "URL Parser -> detecta http e https URL_TAG -> ver beautifulsoup\n",
    "\n",
    "HTML -> tira todas as tags\n",
    "\n",
    "$, euro, libra, yens etc pra MONEY_TAG\n",
    "\n",
    "numeros para NUMBER_TAG\n",
    "\n",
    "tokenizar\n",
    "\n",
    "stemming\n",
    "\n",
    "tirar stopwords\n",
    "\n",
    "selecionar só as palavras mais frequentes\n",
    "\n",
    "checar caracteres estranho em geral, tipo chines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50dbd241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTextParser(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, to_lower=True, url_subs=True, money_subs=True, number_subs=True, punctuation_subs=True):\n",
    "        self.to_lower = to_lower\n",
    "        self.url_subs = url_subs\n",
    "        self.money_subs = money_subs\n",
    "        self.number_subs = number_subs\n",
    "        self.punctuation_subs = punctuation_subs\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        X_og = X.copy()\n",
    "            \n",
    "        if self.url_subs:\n",
    "            url_regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "            X[:, content_ix] = np.array([re.sub(url_regex, \" url_marker \", text) for text in X[:, content_ix]])\n",
    "        \n",
    "        if self.money_subs:\n",
    "            currency_regex = f\"(USD)|(EUR)|(GBP)|[{''.join(chr(i) for i in range(0xffff) if unicodedata.category(chr(i)) == 'Sc')}]\"\n",
    "            X[:, content_ix] = np.array([re.sub(currency_regex, \" currency_marker \", text) for text in X[:, content_ix]])\n",
    "        \n",
    "        if self.number_subs:\n",
    "            number_regex = \"(\\d*\\.?\\d+|\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\" # \"(?:^|\\s)(\\d*\\.?\\d+|\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)(?!\\S)\"\n",
    "            X[:, content_ix] = np.array([re.sub(number_regex, \" number_marker \", text) for text in X[:, content_ix]])\n",
    "        \n",
    "        if self.punctuation_subs:\n",
    "            X[:, content_ix] = np.array([\n",
    "                re.sub(\"\\?\", \" interrogation_marker \", re.sub(\"\\!\", \" exclamation_marker \", text)) \n",
    "                for text in X[:, content_ix]\n",
    "            ])\n",
    "            \n",
    "        if self.to_lower:\n",
    "            X[:, content_ix] = np.array([text.lower() for text in X[:, content_ix]])\n",
    "            \n",
    "        return X\n",
    "    \n",
    "text_parser = MyTextParser()\n",
    "text_parsed_emails = text_parser.transform(parsed_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b8c6c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc[0]))\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', analyzer=stemmed_words, max_features=50000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d92073c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7479, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a3523f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "        ('email', MyEmailParser()),\n",
    "        ('text', MyTextParser()),\n",
    "        ('vectorize', vectorizer)\n",
    "    ])\n",
    "\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train.values) #[:1000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0271144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "294ca9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985292151357134"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_prepared, y_train)\n",
    "log_reg.score(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22717414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(log_reg, X_train_prepared, y_train,\n",
    "                         scoring=\"accuracy\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b264673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_prepared = full_pipeline.transform(X_test.values) #[:1000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a624ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4101604278074866"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "log_reg.score(X_test_prepared, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b73f776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d6e574c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\VICTOR~1\\AppData\\Local\\Temp/ipykernel_45956/1750110106.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_prepared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\ML\\Hands On ML\\my_env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\Hands On ML\\my_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1655\u001b[0m     \"\"\"\n\u001b[1;32m-> 1656\u001b[1;33m     p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[0;32m   1657\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1658\u001b[0m                                                  \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\Hands On ML\\my_env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\Hands On ML\\my_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1462\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1464\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1465\u001b[0m                                     pos_label)\n\u001b[0;32m   1466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\Hands On ML\\my_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1275\u001b[0m                          str(average_options))\n\u001b[0;32m   1276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1277\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1278\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\Hands On ML\\my_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m     83\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\Hands On ML\\my_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;31m# Invalid inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m     if y.ndim > 2 or (y.dtype == object and len(y) and\n\u001b[0m\u001b[0;32m    289\u001b[0m                       not isinstance(y.flat[0], str)):\n\u001b[0;32m    290\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'unknown'\u001b[0m  \u001b[1;31m# [[[1, 2]]] or [obj_1] and not [\"label_1\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": [
    "precision_score(X_test_prepared, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1378b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(X_test_prepared, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3965394",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(X_test_prepared, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67f12c5",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "contar a ocorrencia de cada palavra (binario ou frequencia?)\n",
    "\n",
    "selecionar mais frequentes\n",
    "\n",
    "tirar stopwords\n",
    "\n",
    "pontuação provavelmente contar (!, ?)\n",
    "\n",
    "tirar header do email (separar texto na primeira quebra de linha dupla (acho)) ou nao tirar?? pode avaliar assunto e quem enviou\n",
    "\n",
    "substituir urls por URL, numeros por NUMBER, $ por MONEY talvez\n",
    "\n",
    "stemming\n",
    "\n",
    "tratar html </>\n",
    "\n",
    "replies? \\t |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca98452",
   "metadata": {},
   "source": [
    "caracteres estranhos ?? chines etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
